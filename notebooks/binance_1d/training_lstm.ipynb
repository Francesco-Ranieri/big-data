{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/10/24 22:00:15 INFO mlflow.tracking.fluent: Experiment with name 'Training_LSTM' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/102417157825053997', creation_time=1698177615555, experiment_id='102417157825053997', last_update_time=1698177615555, lifecycle_stage='active', name='Training_LSTM', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://localhost:5000\"\n",
    "mlflow.set_experiment('Training_LSTM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Optuna Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.keras\n",
    "import optuna\n",
    "from common import OptunaPruneCallback, mean_absolute_percentage_error_keras, create_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def objective(trial, data, coin):\n",
    "    with mlflow.start_run() as run:\n",
    "        mlflow.keras.autolog(log_models=False)\n",
    "\n",
    "        # Define the search space for hyperparameters\n",
    "        num_layers = trial.suggest_int('num_layers', 1, 4)\n",
    "        units_per_layer = [trial.suggest_int(f'units_layer_{i}', 32, 256, 32) for i in range(num_layers)]\n",
    "        sequence_length = trial.suggest_int('sequence_length', 1, 10)\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-3)\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "        min_max_scaling = trial.suggest_int('min_max_scaling', 0, 1)\n",
    "        layer_type = trial.suggest_categorical('layer_type', ['LSTM', 'RNN'])\n",
    "\n",
    "        layer_class = keras.layers.LSTM if layer_type == 'LSTM' else keras.layers.SimpleRNN \n",
    "\n",
    "        mlflow.log_params({\n",
    "            'coin': coin,\n",
    "            'num_layers': num_layers,\n",
    "            'units_per_layer': units_per_layer,\n",
    "            'sequence_length': sequence_length,\n",
    "            'learning_rate': learning_rate,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'min_max_scaling': min_max_scaling\n",
    "        })\n",
    "\n",
    "        if min_max_scaling == 1:\n",
    "            scaler = MinMaxScaler()\n",
    "            data = scaler.fit_transform(np.array(data))\n",
    "\n",
    "        X, y = create_sequences(data, sequence_length)\n",
    "\n",
    "        # Build and compile the LSTM model\n",
    "        model = keras.Sequential()\n",
    "        for units in units_per_layer[:-1]:\n",
    "            model.add(layer_class(units, activation='relu', return_sequences=True, input_shape=(sequence_length, 1)))\n",
    "            model.add(keras.layers.Dropout(dropout_rate))\n",
    "        model.add(layer_class(units_per_layer[-1], activation='relu', input_shape=(sequence_length, 1)))\n",
    "        model.add(keras.layers.Dropout(dropout_rate))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate, clipvalue=1.0)\n",
    "        model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[mean_absolute_percentage_error_keras])\n",
    "        # Split the data into training and validation sets\n",
    "        _X_train, X_val, _y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(_X_train, _y_train, test_size=0.2, shuffle=False)\n",
    "\n",
    "        # Train the model with early stopping\n",
    "        history = model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            validation_data=(X_val, y_val), \n",
    "            verbose=0,\n",
    "            callbacks=[OptunaPruneCallback(trial=trial)]\n",
    "        )\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        loss = model.evaluate(X_val, y_val)\n",
    "\n",
    "        return loss[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_best_coin(coin, data, best_params):\n",
    "\n",
    "    # Train the final model with the best hyperparameters\n",
    "    # Define the search space for hyperparameters\n",
    "    num_layers = best_params['num_layers']\n",
    "    units_per_layer = [best_params[f'units_layer_{i}'] for i in range(num_layers)]\n",
    "    sequence_length = best_params['sequence_length']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "    dropout_rate = best_params['dropout_rate']\n",
    "    min_max_scaling = best_params['min_max_scaling']\n",
    "    layer_type = best_params['layer_type']\n",
    "\n",
    "    layer_class = keras.layers.LSTM if layer_type == 'LSTM' else keras.layers.SimpleRNN \n",
    "\n",
    "    if min_max_scaling == 1:\n",
    "        scaler = MinMaxScaler()\n",
    "        data = scaler.fit_transform(np.array(data))\n",
    "\n",
    "    X, y = create_sequences(data, sequence_length)\n",
    "    _X_train, X_val, _y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(_X_train, _y_train, test_size=0.2, shuffle=False)\n",
    "    # concatenate train and validation sets\n",
    "    X_train = np.concatenate((X_train, X_val))\n",
    "    y_train = np.concatenate((y_train, y_val))\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"Training_best_model_{coin}\") as run:\n",
    "        # Build and compile the LSTM model\n",
    "        best_model = keras.Sequential()\n",
    "        for units in units_per_layer[:-1]:\n",
    "            best_model.add(layer_class(units, activation='relu', return_sequences=True, input_shape=(sequence_length, 1)))\n",
    "            best_model.add(keras.layers.Dropout(dropout_rate))\n",
    "        best_model.add(layer_class(units_per_layer[-1], activation='relu', input_shape=(sequence_length, 1)))\n",
    "        best_model.add(keras.layers.Dropout(dropout_rate))\n",
    "        best_model.add(keras.layers.Dense(1))\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate, clipvalue=1.0)\n",
    "        best_model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "        best_model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "        from common import register_training_experiment\n",
    "        preds = best_model.predict([X_test])\n",
    "\n",
    "        if min_max_scaling == 1:\n",
    "            preds = scaler.inverse_transform(preds)\n",
    "            y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "        register_training_experiment(y_test, preds, model_name = layer_class, coin = coin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-24 22:00:15,857] A new study created in RDB with name: close_NULSUSDT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 1ms/step - loss: 8.4891e-05 - mean_absolute_percentage_error_keras: 3.0304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-24 22:00:23,324] Trial 0 finished with value: 3.0303986072540283 and parameters: {'num_layers': 1, 'units_layer_0': 160, 'sequence_length': 9, 'learning_rate': 0.0009629433404982634, 'dropout_rate': 0.2737335839391062, 'min_max_scaling': 0, 'layer_type': 'RNN'}. Best is trial 0 with value: 3.0303986072540283.\n",
      "[W 2023-10-24 22:01:20,539] Trial 1 failed with parameters: {'num_layers': 4, 'units_layer_0': 128, 'units_layer_1': 128, 'units_layer_2': 192, 'units_layer_3': 224, 'sequence_length': 14, 'learning_rate': 9.224921740977847e-05, 'dropout_rate': 0.31632166421905744, 'min_max_scaling': 0, 'layer_type': 'LSTM'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_446240/2614825102.py\", line 18, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, data, coin), n_trials=50)\n",
      "  File \"/tmp/ipykernel_446240/2726865205.py\", line 57, in objective\n",
      "    history = model.fit(\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py\", line 569, in safe_patch_function\n",
      "    patch_function.call(call_original, *args, **kwargs)\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py\", line 166, in call\n",
      "    return cls().__call__(original, *args, **kwargs)\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py\", line 177, in __call__\n",
      "    raise e\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py\", line 170, in __call__\n",
      "    return self._patch_implementation(original, *args, **kwargs)\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py\", line 228, in _patch_implementation\n",
      "    result = super()._patch_implementation(original, *args, **kwargs)\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/mlflow/tensorflow/__init__.py\", line 1302, in _patch_implementation\n",
      "    history = original(inst, *args, **kwargs)\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py\", line 552, in call_original\n",
      "    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py\", line 487, in call_original_fn_with_event_logging\n",
      "    original_fn_result = original_fn(*og_args, **og_kwargs)\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py\", line 549, in _original_fn\n",
      "    original_result = original(*_og_args, **_og_kwargs)\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1742, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 825, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 857, in _call\n",
      "    return self._no_variable_creation_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 148, in __call__\n",
      "    return concrete_function._call_flat(\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1349, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function(*args))\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 196, in __call__\n",
      "    outputs = self._bound_context.call_function(\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/tensorflow/python/eager/context.py\", line 1457, in call_function\n",
      "    outputs = execute.execute(\n",
      "  File \"/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "[W 2023-10-24 22:01:20,540] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(study_name\u001b[39m=\u001b[39mcoin, direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m, storage\u001b[39m=\u001b[39mstorage_name, pruner\u001b[39m=\u001b[39mpruner)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Start the optimization process\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(\u001b[39mlambda\u001b[39;49;00m trial: objective(trial, data, coin), n_trials\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Get the best hyperparameters\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(study_name\u001b[39m=\u001b[39mcoin, direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m, storage\u001b[39m=\u001b[39mstorage_name, pruner\u001b[39m=\u001b[39mpruner)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Start the optimization process\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m study\u001b[39m.\u001b[39moptimize(\u001b[39mlambda\u001b[39;00m trial: objective(trial, data, coin), n_trials\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Get the best hyperparameters\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(_X_train, _y_train, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m# Train the model with early stopping\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     X_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     y_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(X_val, y_val), \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[OptunaPruneCallback(trial\u001b[39m=\u001b[39;49mtrial)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m# Evaluate the model on the validation set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training_lstm.ipynb#X10sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_val, y_val)\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:569\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m try_log_autologging_event(\n\u001b[1;32m    560\u001b[0m     AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_patch_function_start,\n\u001b[1;32m    561\u001b[0m     session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    565\u001b[0m     kwargs,\n\u001b[1;32m    566\u001b[0m )\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m patch_is_class:\n\u001b[0;32m--> 569\u001b[0m     patch_function\u001b[39m.\u001b[39;49mcall(call_original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    570\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    571\u001b[0m     patch_function(call_original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:166\u001b[0m, in \u001b[0;36mPatchFunction.call\u001b[0;34m(cls, original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mcls\u001b[39m, original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:177\u001b[0m, in \u001b[0;36mPatchFunction.__call__\u001b[0;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_exception(e)\n\u001b[1;32m    174\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[39m# Regardless of what happens during the `_on_exception` callback, reraise\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[39m# the original implementation exception once the callback completes\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:170\u001b[0m, in \u001b[0;36mPatchFunction.__call__\u001b[0;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    169\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_patch_implementation(original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    171\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    172\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:228\u001b[0m, in \u001b[0;36mwith_managed_run.<locals>.PatchWithManagedRun._patch_implementation\u001b[0;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mlflow\u001b[39m.\u001b[39mactive_run():\n\u001b[1;32m    226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanaged_run \u001b[39m=\u001b[39m create_managed_run()\n\u001b[0;32m--> 228\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_patch_implementation(original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanaged_run:\n\u001b[1;32m    231\u001b[0m     mlflow\u001b[39m.\u001b[39mend_run(RunStatus\u001b[39m.\u001b[39mto_string(RunStatus\u001b[39m.\u001b[39mFINISHED))\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/mlflow/tensorflow/__init__.py:1302\u001b[0m, in \u001b[0;36mautolog.<locals>.FitPatch._patch_implementation\u001b[0;34m(self, original, inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1296\u001b[0m         _logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m   1297\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFailed to log training dataset information to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1298\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMLflow Tracking. Reason: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1299\u001b[0m             e,\n\u001b[1;32m   1300\u001b[0m         )\n\u001b[0;32m-> 1302\u001b[0m history \u001b[39m=\u001b[39m original(inst, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1304\u001b[0m \u001b[39mif\u001b[39;00m log_models:\n\u001b[1;32m   1305\u001b[0m     _log_keras_model(history, args)\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:552\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[0;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39m_og_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_og_kwargs)\n\u001b[1;32m    550\u001b[0m         \u001b[39mreturn\u001b[39;00m original_result\n\u001b[0;32m--> 552\u001b[0m \u001b[39mreturn\u001b[39;00m call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:487\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[0;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    479\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    480\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_start,\n\u001b[1;32m    481\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         og_kwargs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m     original_fn_result \u001b[39m=\u001b[39m original_fn(\u001b[39m*\u001b[39;49mog_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mog_kwargs)\n\u001b[1;32m    489\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    490\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_success,\n\u001b[1;32m    491\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    495\u001b[0m         og_kwargs,\n\u001b[1;32m    496\u001b[0m     )\n\u001b[1;32m    497\u001b[0m     \u001b[39mreturn\u001b[39;00m original_fn_result\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:549\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[0;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[39m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[39m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[39m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[39m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[39mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[1;32m    546\u001b[0m     disable_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    547\u001b[0m     reroute_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    548\u001b[0m ):\n\u001b[0;32m--> 549\u001b[0m     original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39;49m_og_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_og_kwargs)\n\u001b[1;32m    550\u001b[0m     \u001b[39mreturn\u001b[39;00m original_result\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from common import get_dataframe\n",
    "\n",
    "# Normalize the data to the range [0, 1] to help the LSTM model converge faster\n",
    "\n",
    "df = get_dataframe()\n",
    "\n",
    "for coin in df.iloc[:, 1:]:\n",
    "    data = np.array(df[coin]).reshape(-1, 1)\n",
    "\n",
    "    # Create an Optuna study\n",
    "    study_name = coin  # Unique identifier of the study.\n",
    "    storage_name = \"sqlite:///training.db\"\n",
    "    pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
    "    study = optuna.create_study(study_name=coin, direction='minimize', storage=storage_name, pruner=pruner)\n",
    "\n",
    "    # Start the optimization process\n",
    "    study.optimize(lambda trial: objective(trial, data, coin), n_trials=50)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    try:\n",
    "        best_params = study.best_params\n",
    "        print(\"Best Hyperparameters:\", best_params)\n",
    "        evaluate_best_coin(coin, data, best_params)\n",
    "    except ValueError:\n",
    "        print(\"No best hyperparameters found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "price-oracle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
