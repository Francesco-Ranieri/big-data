{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SET UP ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../dev-requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env file if it exists\n",
    "# Don't use dotenv\n",
    "!pip install python-dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "folder = os.path.join(\"../../airflow/assets/binance_1d\")\n",
    "dfs = []\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        dfs.append(pd.read_csv(os.path.join(folder, file), skiprows=1, parse_dates=['Date']))\n",
    "print(dfs.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge all in one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Convert \"date\" column to datetime in all dataframes\n",
    "for df in dfs:\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d', errors=\"coerce\")\n",
    "\n",
    "# Step 2: Find the oldest and newest dates across all dataframes\n",
    "all_dates = [df['Date'] for df in dfs]\n",
    "all_dates_flat = [date for sublist in all_dates for date in sublist if not pd.isnull(date)]\n",
    "\n",
    "oldest_date = '2019-01-01'\n",
    "newest_date = max(all_dates_flat)\n",
    "\n",
    "# Step 3: Create a new dataframe with the date range\n",
    "date_range = pd.date_range(start=oldest_date, end=newest_date, freq='D')  # Daily frequency\n",
    "merged_df = pd.DataFrame({'Date': date_range})\n",
    "\n",
    "# Step 4: Add \"close\" and \"Volume USDT\" columns from each dataframe to the merged_df using list comprehension\n",
    "for df in dfs:\n",
    "    try:\n",
    "        ticker = df['Symbol'].iloc[0]  # Assuming each dataframe has a \"symbol\" column\n",
    "        close_col_name = f'close_{ticker}'\n",
    "        volume_col_name = f'Volume USDT_{ticker}'  # Replace with the actual column name if it's different in your data\n",
    "\n",
    "        df = df.set_index('Date').sort_index()\n",
    "\n",
    "        # Create DataFrames with the \"date\" and \"close\" columns\n",
    "        close_data = df[df.index.isin(date_range)][['Close']]\n",
    "        close_data.rename(columns={'Close': close_col_name}, inplace=True)\n",
    "\n",
    "        # Merge the \"close_data\" into the \"merged_df\"\n",
    "        merged_df = pd.merge(merged_df, close_data, left_on='Date', right_index=True, how='left')\n",
    "\n",
    "        # Add the \"Volume USDT\" column to the merged_df (replace 'Volume USDT' with the actual column name if it's different)\n",
    "        # merged_df[volume_col_name] = df['Volume USDT']\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f'Error on coin {ticker}: {e}')\n",
    "\n",
    "\n",
    "# print number of columns -1 of merged_df\n",
    "print(merged_df.columns.__len__()-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD Experiment from MLFLOW\n",
    "\n",
    "Run \n",
    "\n",
    "``` python\n",
    "cd mlflow\n",
    "mlflow server\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import json\n",
    "\n",
    "experiment_id = \"110357928989408424\"\n",
    "run_id = \"35f1bb80732f433297fda78e6638feab\"\n",
    "\n",
    "# Mlfow Section\n",
    "experiments = mlflow.search_runs(experiment_ids=experiment_id)\n",
    "experiment = experiments.loc[experiments['run_id'] == run_id]\n",
    "\n",
    "# Use eval() to convert the string to a list of tuples\n",
    "data_list = eval(experiment[\"params.Cluster_Labels\"].tolist()[0])\n",
    "\n",
    "# Convert the list of tuples to a dictionary\n",
    "data_dict = dict(data_list)\n",
    "\n",
    "# Create a map where keys are the values from the original dictionary\n",
    "cripto_clusters = {}\n",
    "for key, value in data_dict.items():\n",
    "    if value in cripto_clusters:\n",
    "        cripto_clusters[value].append(key)\n",
    "    else:\n",
    "        cripto_clusters[value] = [key]\n",
    "\n",
    "clusters_data = {}\n",
    "\n",
    "# loop on key and value of cripto_clusters\n",
    "for cluster, criptos in cripto_clusters.items():\n",
    "    _criptos = criptos + ['Date']\n",
    "    clusters_data[cluster] = merged_df[_criptos]\n",
    "\n",
    "# Clusters now contains a dictionary with the cluster number as key and the dataframe with the criptos as value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELS SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def adfuller_test(time_series, significance_level=0.05):\n",
    "    \"\"\"\n",
    "    Perform Augmented Dickey-Fuller (ADF) test for stationarity.\n",
    "\n",
    "    Parameters:\n",
    "    - time_series: A pandas Series or NumPy array containing the time series data.\n",
    "    - significance_level: The significance level for the test (default is 0.05).\n",
    "\n",
    "    Returns:\n",
    "    - ADF test result and p-value.\n",
    "    - A string indicating the stationarity based on the p-value.\n",
    "    \"\"\"\n",
    "\n",
    "    result = adfuller(time_series)\n",
    "    adf_statistic = result[0]\n",
    "    p_value = result[1]\n",
    "\n",
    "    if p_value <= significance_level:\n",
    "        stationarity = \"Stationary (p <= {0})\".format(significance_level)\n",
    "    else:\n",
    "        stationarity = \"Non-Stationary (p > {0})\".format(significance_level)\n",
    "\n",
    "    return adf_statistic, p_value, stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_and_plot_price_changes(cluster_data, column_name, window_size=10):\n",
    "    \"\"\"\n",
    "    Calculate and plot first-order percentage differences, rolling mean, and rolling standard deviation.\n",
    "\n",
    "    Parameters:\n",
    "    - data: A pandas DataFrame containing a 'date' index and the specified cryptocurrency price column.\n",
    "    - column_name: The name of the column representing cryptocurrency prices.\n",
    "    - window_size: The window size for the rolling statistics (default is 10).\n",
    "\n",
    "    Returns:\n",
    "    - None (plots the results).\n",
    "    \"\"\"\n",
    "    data = cluster_data.copy()\n",
    "    if 'Date' not in data.columns:\n",
    "        raise ValueError(\"The 'data' DataFrame must contain a 'date' column as the index.\")\n",
    "\n",
    "    if column_name not in data.columns:\n",
    "        raise ValueError(f\"The specified column '{column_name}' is not found in the DataFrame.\")\n",
    "    \n",
    "    # Calculate daily percentage changes\n",
    "    data['PriceChange'] = data[column_name].pct_change() * 100\n",
    "\n",
    "    # Calculate rolling mean and rolling standard deviation\n",
    "    data['RollingMean'] = data['PriceChange'].rolling(window=window_size).mean()\n",
    "    data['RollingStd'] = data['PriceChange'].rolling(window=window_size).std()\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(data.index, data['PriceChange'], label='Price Change (%)', color='blue')\n",
    "    plt.plot(data.index, data['RollingMean'], label=f'Rolling Mean ({window_size}-hour)', color='green')\n",
    "    plt.plot(data.index, data['RollingStd'], label=f'Rolling Std Deviation ({window_size}-hour)', color='red')\n",
    "\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Percentage Change / Rolling Statistics')\n",
    "    plt.title(f'{column_name} Price Changes and Rolling Statistics')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in cripto_clusters:\n",
    "    print(f'Cluster {cluster}: {cripto_clusters[cluster]}\\n')\n",
    "    for cripto in clusters_data[cluster]:\n",
    "        if cripto != 'Date':\n",
    "            print(f'Analyzing: {cripto}')\n",
    "\n",
    "            adf_statistic, p_value, stationarity = adfuller_test(clusters_data[cluster][cripto])\n",
    "            print(\"ADF Statistic:\", adf_statistic)\n",
    "            print(\"p-value:\", p_value)\n",
    "            print(\"Stationarity:\", stationarity)\n",
    "\n",
    "            calculate_and_plot_price_changes(clusters_data[cluster], cripto)\n",
    "            print(\"\\n\")\n",
    "        print(\"\\n---------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivariate Time Series - Vector Auto Regression (VAR)\n",
    "\n",
    "[Source](https://www.analyticsvidhya.com/blog/2018/09/multivariate-time-series-guide-forecasting-modeling-python-codes/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "\n",
    "cluster = clusters_data[0]\n",
    "\n",
    "def mts_var_training(cluster_data):\n",
    "    \n",
    "    # Data preparation\n",
    "\n",
    "    # Step 1: Remove the \"date\" column\n",
    "    data = cluster_data.drop(['Date'], axis=1)\n",
    "    cols = data.columns\n",
    "    # Step 2: Set the \"date\" column as the index\n",
    "    data.index = cluster_data.Date\n",
    "\n",
    "    # Step 3: Dealing with missing values --> already done\n",
    "\n",
    "    # Step 4: Split the data into train and test sets\n",
    "    train_size = int(len(data) * 0.7)\n",
    "    test_size = (len(data) - train_size) / 2\n",
    "\n",
    "    train = data.iloc[0:train_size] \n",
    "    valid = data.iloc[train_size:int(len(data) - test_size)]\n",
    "    test = data.iloc[int(train_size + test_size):len(data)]\n",
    "\n",
    "    print('train size: ', len(train))\n",
    "    print('valid size: ', len(valid))\n",
    "    print('test size: ', len(test))\n",
    "    print('total size: ', len(data))\n",
    "    print(\"\\n\")\n",
    "    assert len(data) == len(train) + len(valid) + len(test)\n",
    "\n",
    "    model = VAR(endog=train)\n",
    "    model_fit = model.fit()\n",
    "    print(model_fit)\n",
    "\n",
    "    # make prediction on validation\n",
    "    prediction = model_fit.forecast(model_fit.endog, steps=len(valid))\n",
    "\n",
    "    #converting predictions to dataframe\n",
    "    pred = pd.DataFrame(index=range(0,len(prediction)),columns=[cols])\n",
    "    for j in range(0, len(cols)):\n",
    "        for i in range(0, len(prediction)):\n",
    "            pred.iloc[i][j] = prediction[i][j]\n",
    "\n",
    "    #check rmse\n",
    "    for i in cols:\n",
    "        print('RMSE value for', i, 'is : ', sqrt(mean_squared_error(pred[i], valid[i])))\n",
    "\n",
    "    return prediction, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 2: ['close_ETHUSDT', 'close_BNBUSDT', 'close_BTCUSDT', 'close_TRXUSDT']\n",
      "\n",
      "train size:  1226\n",
      "valid size:  263\n",
      "test size:  263\n",
      "total size:  1752\n",
      "\n",
      "\n",
      "<statsmodels.tsa.vector_ar.var_model.VARResultsWrapper object at 0x7fd770d4a700>\n",
      "RMSE value for close_ETHUSDT is :  315.2080548562406\n",
      "RMSE value for close_BNBUSDT is :  85.0057633834698\n",
      "RMSE value for close_BTCUSDT is :  5960.647829501882\n",
      "RMSE value for close_TRXUSDT is :  0.017235701377382416\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Cluster 0: ['close_QTUMUSDT', 'close_VETUSDT', 'close_XRPUSDT', 'close_XLMUSDT', 'close_ICXUSDT', 'close_IOTAUSDT', 'close_ADAUSDT', 'close_ETCUSDT', 'close_NEOUSDT', 'close_LTCUSDT']\n",
      "\n",
      "train size:  1226\n",
      "valid size:  263\n",
      "test size:  263\n",
      "total size:  1752\n",
      "\n",
      "\n",
      "<statsmodels.tsa.vector_ar.var_model.VARResultsWrapper object at 0x7fd770cf3d90>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/tmp/ipykernel_221756/1540326292.py:46: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  pred.iloc[i][j] = prediction[i][j]\n",
      "/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/tmp/ipykernel_221756/1540326292.py:46: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  pred.iloc[i][j] = prediction[i][j]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value for close_QTUMUSDT is :  2.4671660177320085\n",
      "RMSE value for close_VETUSDT is :  0.01933030801617754\n",
      "RMSE value for close_XRPUSDT is :  0.13595817288349588\n",
      "RMSE value for close_XLMUSDT is :  0.07409756398581484\n",
      "RMSE value for close_ICXUSDT is :  0.47981077187734766\n",
      "RMSE value for close_IOTAUSDT is :  0.34533006544278005\n",
      "RMSE value for close_ADAUSDT is :  0.23066477800626328\n",
      "RMSE value for close_ETCUSDT is :  8.513498167204158\n",
      "RMSE value for close_NEOUSDT is :  13.391528379037657\n",
      "RMSE value for close_LTCUSDT is :  42.466410704038836\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Cluster 1: ['close_EOSUSDT', 'close_ONTUSDT', 'close_NULSUSDT']\n",
      "\n",
      "train size:  1226\n",
      "valid size:  263\n",
      "test size:  263\n",
      "total size:  1752\n",
      "\n",
      "\n",
      "<statsmodels.tsa.vector_ar.var_model.VARResultsWrapper object at 0x7fd770cf3310>\n",
      "RMSE value for close_EOSUSDT is :  2.263578235903304\n",
      "RMSE value for close_ONTUSDT is :  0.524117880645247\n",
      "RMSE value for close_NULSUSDT is :  0.2368666152294531\n",
      "\n",
      "---------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gianfranco/Desktop/uni/price-oracle/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/tmp/ipykernel_221756/1540326292.py:46: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  pred.iloc[i][j] = prediction[i][j]\n"
     ]
    }
   ],
   "source": [
    "for cluster in cripto_clusters:\n",
    "    print(f'Cluster {cluster}: {cripto_clusters[cluster]}\\n')\n",
    "    prediction, valid = mts_var_training(clusters_data[cluster])\n",
    "    print(\"\\n---------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.263578235903304"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe\n",
    "df = pd.DataFrame()\n",
    "df[\"predicton\"] = prediction[:, 0]\n",
    "df[\"close_EOSUSDT\"] = valid['close_EOSUSDT'].values\n",
    "\n",
    "# Calculate MSE and RMSE for the prediction\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(df[\"close_EOSUSDT\"], df[\"predicton\"])\n",
    "mse\n",
    "rmse = sqrt(mse)\n",
    "rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivariate Time Series Forecasting with Deep Learning\n",
    "\n",
    "[Source 1](https://towardsdatascience.com/multivariate-time-series-forecasting-with-deep-learning-3e7b3e2d2bcf) \\\n",
    "[Source 2](https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def get_train_test_data(cluster_data, n_steps=10, test_size=0.2, shuffle=False):\n",
    "\n",
    "    data = cluster_data.copy() \n",
    "\n",
    "    data['Date'] = pd.to_datetime(data['Date'])  # Convert the 'date' column to datetime\n",
    "\n",
    "    # Sort the data by date\n",
    "    data = data.sort_values(by='Date')\n",
    "\n",
    "    # Define the number of previous time steps to consider for prediction\n",
    "    n_steps = 10  # You can adjust this value\n",
    "\n",
    "    # Create input data by shifting prices to create sequences\n",
    "    X = data.drop(columns=['Date']).values\n",
    "    X_seq = [X[i:i + n_steps] for i in range(len(X) - n_steps)]\n",
    "\n",
    "    # Shift the closing price to predict the next closing price\n",
    "    y = data.drop(columns=['Date']).shift(-n_steps).values\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    _X_train, X_test, _y_train, y_test = train_test_split(X_seq, y[:-n_steps], test_size=0.2, shuffle=False)\n",
    "\n",
    "    # split the training set into training and validation sets\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(_X_train, _y_train, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Reshape the data to 3D for LSTM\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    X_valid = np.array(X_valid)\n",
    "    y_valid = np.array(y_valid)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print('y_train shape:', y_train.shape)\n",
    "    print('X_valid shape:', X_valid.shape)\n",
    "    print('y_valid shape:', y_valid.shape)\n",
    "    print('X_test shape:', X_test.shape)\n",
    "    print('y_test shape:', y_test.shape)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gianfranco/Desktop/uni/price-oracle/notebooks/binance_1d/training.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_error\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Create a function to calculate RMSE\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def lstm_training(cluster_data, n_steps=10, test_size=0.2, shuffle=False):\n",
    "    data = cluster_data.copy()\n",
    "    X_train, X_valid, X_test, y_train, y_valid, y_test = get_train_test_data(data, n_steps, test_size, shuffle)\n",
    "    \n",
    "    # Define the model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(64, activation='relu', input_shape=(n_steps, X_train.shape[2]), return_sequences=True),\n",
    "        tf.keras.layers.LSTM(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(X_train.shape[2])\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_valid, y_valid))\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate and print RMSE\n",
    "    for i, cripto in enumerate(data.columns[:-1]):\n",
    "        rmse = calculate_rmse(y_test[:, i], y_pred[:, i])\n",
    "        print(f'Root Mean Squared Error (RMSE) for {cripto}: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in cripto_clusters:\n",
    "    print(f'Cluster {cluster}: {cripto_clusters[cluster]}\\n')\n",
    "    lstm_training(clusters_data[cluster])\n",
    "    print(\"\\n---------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Foo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Define a function to calculate RMSE\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Simulate the Foo Model\n",
    "def foo_model(x):\n",
    "    #x = x[1]\n",
    "    return x + (random.randint(-1, 1) * 0.2 * x)\n",
    "\n",
    "def foo_model_training(cluster_data):\n",
    "    _, X_valid, _, _, y_valid, _ = get_train_test_data(cluster_data)\n",
    "    data = cluster_data.copy()\n",
    "    for i, cripto in enumerate(data.columns[:-1]):\n",
    "        predictions = foo_model(clusters_data[cluster][\"close_EOSUSDT\"].values)\n",
    "        rmse = calculate_rmse(y_valid[i], predictions)\n",
    "        print(f'Root Mean Squared Error (RMSE) for {cripto}: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6184"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_data[cluster][\"close_EOSUSDT\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 2: ['close_ETHUSDT', 'close_BNBUSDT', 'close_BTCUSDT', 'close_TRXUSDT']\n",
      "\n",
      "X_train shape: (1114, 10, 4)\n",
      "y_train shape: (1114, 4)\n",
      "X_valid shape: (279, 10, 4)\n",
      "y_valid shape: (279, 4)\n",
      "X_test shape: (349, 10, 4)\n",
      "y_test shape: (349, 4)\n",
      "\n",
      "\n",
      "\n",
      "Root Mean Squared Error (RMSE) for close_ETHUSDT: 2812.8998\n",
      "Root Mean Squared Error (RMSE) for close_BNBUSDT: 4371.4659\n",
      "Root Mean Squared Error (RMSE) for close_BTCUSDT: 1703.3081\n",
      "Root Mean Squared Error (RMSE) for close_TRXUSDT: 2403.2470\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Cluster 0: ['close_QTUMUSDT', 'close_VETUSDT', 'close_XRPUSDT', 'close_XLMUSDT', 'close_ICXUSDT', 'close_IOTAUSDT', 'close_ADAUSDT', 'close_ETCUSDT', 'close_NEOUSDT', 'close_LTCUSDT']\n",
      "\n",
      "X_train shape: (1114, 10, 10)\n",
      "y_train shape: (1114, 10)\n",
      "X_valid shape: (279, 10, 10)\n",
      "y_valid shape: (279, 10)\n",
      "X_test shape: (349, 10, 10)\n",
      "y_test shape: (349, 10)\n",
      "\n",
      "\n",
      "\n",
      "Root Mean Squared Error (RMSE) for close_QTUMUSDT: 2.3333\n",
      "Root Mean Squared Error (RMSE) for close_VETUSDT: 5.6839\n",
      "Root Mean Squared Error (RMSE) for close_XRPUSDT: 6.6207\n",
      "Root Mean Squared Error (RMSE) for close_XLMUSDT: 8.3970\n",
      "Root Mean Squared Error (RMSE) for close_ICXUSDT: 1.0221\n",
      "Root Mean Squared Error (RMSE) for close_IOTAUSDT: 1.7199\n",
      "Root Mean Squared Error (RMSE) for close_ADAUSDT: 5.0615\n",
      "Root Mean Squared Error (RMSE) for close_ETCUSDT: 2.0871\n",
      "Root Mean Squared Error (RMSE) for close_NEOUSDT: 13.2727\n",
      "Root Mean Squared Error (RMSE) for close_LTCUSDT: 16.1480\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Cluster 1: ['close_EOSUSDT', 'close_ONTUSDT', 'close_NULSUSDT']\n",
      "\n",
      "X_train shape: (1114, 10, 3)\n",
      "y_train shape: (1114, 3)\n",
      "X_valid shape: (279, 10, 3)\n",
      "y_valid shape: (279, 3)\n",
      "X_test shape: (349, 10, 3)\n",
      "y_test shape: (349, 3)\n",
      "\n",
      "\n",
      "\n",
      "Root Mean Squared Error (RMSE) for close_EOSUSDT: 0.5083\n",
      "Root Mean Squared Error (RMSE) for close_ONTUSDT: 0.0331\n",
      "Root Mean Squared Error (RMSE) for close_NULSUSDT: 0.3370\n",
      "\n",
      "---------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cluster in cripto_clusters:\n",
    "    print(f'Cluster {cluster}: {cripto_clusters[cluster]}\\n')\n",
    "    foo_model_training(clusters_data[cluster])\n",
    "    print(\"\\n---------------------------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "price-oracle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
